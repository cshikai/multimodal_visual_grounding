{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d12bb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "CAP = 15\n",
    "# CAP DATA AT 20 OR 15.\n",
    "\n",
    "\n",
    "\n",
    "def word_count(string):\n",
    "    return len(string.split(\" \"))\n",
    "\n",
    "for i in ['train','valid']:\n",
    "    for j in ['flickr','mscoco','visualgenome']:\n",
    "        f = '/data/manifest/{}/{}_manifest.csv'.format(j,i)\n",
    "        print(f)\n",
    "        df = pd.read_csv(f)\n",
    "        df['wordcount'] = df.caption.apply(word_count)\n",
    "        print('max val', df.wordcount.max())\n",
    "        print(df[df.wordcount==df.wordcount.max()]['caption'].values)\n",
    "        \n",
    "        cramp_df = df[df.wordcount<=CAP]\n",
    "        print('{} out of {} is 30 len or below. thats {} percent'.format(len(cramp_df),len(df),len(cramp_df)/len(df)))\n",
    "        print('=========\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc1467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.arange(8).reshape((2,2,2)).float()\n",
    "\n",
    "b = torch.nn.functional.normalize(a,p=2,dim=-1)\n",
    "print(b)\n",
    "\n",
    "c = []\n",
    "for i in range((a.shape[1])):\n",
    "    d = torch.nn.functional.normalize(a[:,i:i+1,:],p=2,dim=-1)\n",
    "    c.append(d)\n",
    "    \n",
    "c = torch.cat(c,dim=1)\n",
    "c==b\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d624f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "learning_rate = 2\n",
    "model = torch.nn.Linear(2, 1)\n",
    "def get_learning_rate(epoch):\n",
    "    if epoch < 10:\n",
    "        return 1\n",
    "    elif epoch < 15:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0.25\n",
    "    \n",
    "optimizer = torch.optim.Adam(\n",
    "                model.parameters(), lr=learning_rate)\n",
    "            \n",
    "    \n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "                optimizer, lr_lambda=get_learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "lrs = []\n",
    "\n",
    "for i in range(20):\n",
    "    optimizer.step()\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "#     print(\"Factor = \", round(0.65 ** i,3),\" , Learning Rate = \",round(optimizer.param_groups[0][\"lr\"],3))\n",
    "    scheduler.step()\n",
    "    \n",
    "print(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5366f55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import os\n",
    "root_folder = '/data/image_manifest/flickr/train'\n",
    "data = dd.read_parquet(os.path.join(root_folder),\n",
    "                                    \n",
    "                                    )  # this is lazy loading, its not actually loading into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceda8e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.text_tensor.dataset import VGTextDataset\n",
    "from config.config import cfg\n",
    "train_dataset = VGTextDataset('train', cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1771d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a666a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b9305",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from clearml import Dataset, Task\n",
    "\n",
    "DATA_PROJECT_NAME = \"datasets/multimodal\"\n",
    "\n",
    "\n",
    "TASK_NAME = \"visual_grounding_training_data_generation\"\n",
    "\n",
    "DATASET_ROOT = '/data/processed/'\n",
    "\n",
    "OUTPUT_URL = \"s3://experiment-logging/multimodal\"\n",
    "\n",
    "\n",
    "input_train_dataset_paths = []\n",
    "input_valid_dataset_paths = []\n",
    "\n",
    "args = {\n",
    "\n",
    "    'num_captions': 5,\n",
    "    'npartitions': 100,\n",
    "    'batch_size': 4,\n",
    "    'input_manifests': ['71a397b04b5d476bb5543306269e28af', ],\n",
    "    'dataset_name': \"VisualGround_FLICKR_manifest_100paritions_4_batch\"\n",
    "}\n",
    "\n",
    "\n",
    "TEMP_PATH = '/tmp'\n",
    "if not os.path.exists(TEMP_PATH):\n",
    "    os.makedirs(TEMP_PATH)\n",
    "for dataset_id in args['input_manifests']:\n",
    "    dataset = Dataset.get(dataset_id=dataset_id)\n",
    "    local_root_path = dataset.get_mutable_local_copy(\n",
    "        os.path.join(TEMP_PATH, dataset_id))\n",
    "\n",
    "    input_train_dataset_paths.append(os.path.join(\n",
    "        local_root_path, 'train_manifest.csv'))\n",
    "\n",
    "    valid_path = os.path.join(\n",
    "        local_root_path, 'valid_manifest.csv')\n",
    "\n",
    "    if os.path.exists(valid_path):\n",
    "        input_valid_dataset_paths.append(valid_path)\n",
    "print(input_train_dataset_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a26058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "grey = 'mscoco/COCO_train2014_000000095753.jpg'\n",
    "image = Image.open(os.path.join(\n",
    "            '/data/', grey))\n",
    "rgbimg = Image.new(\"RGB\", image.size)\n",
    "rgbimg.paste(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51398d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rgbimg.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5601a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grey.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8708449c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rgbimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb068ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "valid_data = pd.read_csv('/data/parquet/flickr_mscoco_visualgenome/valid/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "380fdeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = []\n",
    "for filename in valid_data.filename:\n",
    "    if not check_exist(os.path.join('/data',filename)):\n",
    "        missing.append(filename)\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31d96deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_exist(f):\n",
    "    return os.path.exists(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6ded7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19eaa50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_df = pd.read_csv('/data/manifests/flickr/valid_manifest.csv')\n",
    "\n",
    "# manifest_df = manifest_df.groupby(\n",
    "#             'filename').apply(lambda x: x.head(self.num_captions)).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa30b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_captions = manifest_df.groupby('filename').filter(lambda x : len(x) >= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6309bc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    4482\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_captions.groupby('filename').apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7a0b57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
