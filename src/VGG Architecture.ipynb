{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c13206d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Pytorch pre-release version 1.10.0a0+3fd9dcf - assuming intent to test it\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "from collections import OrderedDict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "81a7b117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /models/cache/hub/checkpoints/vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb56ca12b6e4ede842e87826a5d4902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/528M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ['TORCH_HOME'] = '/models/cache' #setting the environment variable\n",
    "resnet = models.vgg16(pretrained=True)\n",
    "\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d9de0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualFeatures(pl.LightningModule):\n",
    "\n",
    "# layer ids correspond to layers 4.1,4.3,5.1,5.3 in the vgg16 architecture\n",
    "    FEATURE_LAYERS_ID = ['18','22','25','29']\n",
    "    M = 18\n",
    "    D = 1024\n",
    "    NUM_CONV_LAYERS = 3\n",
    "    alpha = 0.25\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        image_model = models.vgg16(pretrained=False)\n",
    "        checkpoint = torch.load('/models/cache/hub/checkpoints/vgg16-397923af.pth')\n",
    "        image_model.load_state_dict(checkpoint)\n",
    "        self.pretrained_model = list(image_model.children())[0]\n",
    "        \n",
    "        for parameter in self.pretrained_model.parameters():\n",
    "            parameter.requires_grad = False\n",
    "        \n",
    "        self.raw_visual_features = OrderedDict()\n",
    "        self.visual_features = OrderedDict()\n",
    "        \n",
    "        #no explict need to reference these hooks ,but reference them for potential future use\n",
    "        self.forward_hooks = []\n",
    "        \n",
    "        \n",
    "        for l in list(self.pretrained_model._modules.keys()):\n",
    "            \n",
    "            if l in self.FEATURE_LAYERS_ID:\n",
    "                self.forward_hooks.append(getattr(self.pretrained_model,l).register_forward_hook(self._forward_hook(l)) )\n",
    "        \n",
    "        \n",
    "        self.resize = torch.nn.Upsample(size=(self.M,self.M), scale_factor=None, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        for l in self.FEATURE_LAYERS_ID:\n",
    "            for i in range(self.NUM_CONV_LAYERS):\n",
    "                layer_name = l+'_conv_' + str(i)\n",
    "                if i == 0:\n",
    "                    setattr(self,layer_name,torch.nn.Conv2d(512, self.D,  kernel_size = (1,1), stride=1))\n",
    "                else:\n",
    "                    setattr(self,layer_name,torch.nn.Conv2d(self.D, self.D,  kernel_size = (1,1), stride=1))\n",
    "        self.leaky_relu = torch.nn.LeakyReLU(self.alpha, inplace=True)\n",
    "    def _forward_hook(self,layer_id):\n",
    "        def hook(module,input,output):\n",
    "            self.raw_visual_features[layer_id] = output\n",
    "        return hook\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.pretrained_model(x)\n",
    "        for l in self.FEATURE_LAYERS_ID:\n",
    "            x = self.resize(self.raw_visual_features[l])\n",
    "            for i in range(self.NUM_CONV_LAYERS):\n",
    "                layer_name = l+'_conv_' + str(i)\n",
    "                x = getattr(self,layer_name)(x)\n",
    "                x = self.leaky_relu(x)\n",
    "            self.visual_features[l] = x\n",
    "        x = torch.stack([self.visual_features[l] for l in self.visual_features.keys()],1)\n",
    "        x = torch.nn.functional.normalize(x ,p=2,dim=2).permute((0,3,4,1,2))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "189061c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 18, 18, 4, 1024])\n"
     ]
    }
   ],
   "source": [
    "sample = torch.rand(1,3,224,224)\n",
    "viz = VisualFeatures()\n",
    "result = viz(sample)\n",
    "print(result.shape)\n",
    "# for key,value in result.items():\n",
    "#     print(value.shape)\n",
    "# viz.eval()\n",
    "# script = viz.to_torchscript()\n",
    "# torch.jit.save(script, os.path.join('/models',\"model.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "23e1512c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 18, 18])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(result,dim=2,p=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fa126b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('10',\n",
       "              tensor([[[[ 5.7290,  3.7643,  4.2850,  ...,  6.4441,  6.9683, 10.6676],\n",
       "                        [ 5.2510,  3.3421,  4.2545,  ...,  3.5091,  2.2189,  5.6018],\n",
       "                        [ 3.9606,  4.4606,  4.3926,  ...,  4.4884,  2.5008,  4.4092],\n",
       "                        ...,\n",
       "                        [ 4.0569,  1.0795,  2.2917,  ...,  0.4592,  1.7108,  3.5214],\n",
       "                        [ 5.0973,  2.7780,  1.9630,  ...,  3.1584,  1.2424,  4.1274],\n",
       "                        [ 9.1784,  8.0466,  6.0983,  ...,  7.0364,  6.0461,  9.3533]],\n",
       "              \n",
       "                       [[ 1.2641,  0.0000,  1.6852,  ...,  0.6854,  0.1268,  3.2701],\n",
       "                        [ 0.6663,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.0000,  1.0350,  ...,  0.0000,  0.0000,  2.4748],\n",
       "                        ...,\n",
       "                        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  4.9356],\n",
       "                        [ 3.3929,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.6705],\n",
       "                        [ 0.0000,  0.0000,  0.0000,  ...,  3.6498,  2.8196,  3.0381]],\n",
       "              \n",
       "                       [[ 0.5547,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                        [ 0.9603,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                        ...,\n",
       "                        [ 2.1920,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                        [ 1.2453,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                        [ 2.7286,  0.9284,  0.8075,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.8264,  0.0000,  0.0000,  ...,  0.0000,  2.1242,  0.0000],\n",
       "                        [ 4.9846,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.3444],\n",
       "                        [ 0.1944,  0.0000,  0.0000,  ...,  0.0000,  0.0411,  0.0000],\n",
       "                        ...,\n",
       "                        [ 3.0652,  0.0784,  0.0000,  ...,  2.9066,  0.0000,  0.0000],\n",
       "                        [ 1.0560,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                        [ 6.8207,  5.8127,  0.9966,  ...,  0.0000,  3.3423,  0.0000]],\n",
       "              \n",
       "                       [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.1050],\n",
       "                        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                        ...,\n",
       "                        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "              \n",
       "                       [[ 1.9818,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                        [ 2.6124,  0.0000,  0.0000,  ...,  0.0000,  0.3427,  0.0000],\n",
       "                        [ 1.9004,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                        ...,\n",
       "                        [ 0.5709,  0.0000,  0.0000,  ...,  0.3239,  0.0000,  0.0000],\n",
       "                        [ 1.1456,  0.0000,  0.0000,  ...,  0.2466,  0.0000,  0.0000],\n",
       "                        [ 1.3964,  1.0515,  0.0000,  ...,  0.9279,  0.0000,  0.0000]]]])),\n",
       "             ('13',\n",
       "              tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        ...,\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "              \n",
       "                       [[0.1346, 0.0000, 0.0000,  ..., 0.2442, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        ...,\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "              \n",
       "                       [[5.1621, 0.0000, 0.0000,  ..., 1.2120, 1.0189, 0.5056],\n",
       "                        [4.4032, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [1.7505, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        ...,\n",
       "                        [2.1115, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.9748, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0.0000, 0.0000, 0.1943,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        ...,\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.1507, 1.4911, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "              \n",
       "                       [[2.3711, 3.5221, 4.7173,  ..., 3.7955, 2.2401, 3.5419],\n",
       "                        [0.7398, 2.9430, 4.5054,  ..., 3.9592, 1.4623, 4.3516],\n",
       "                        [1.9871, 6.3796, 7.9726,  ..., 7.7947, 5.5748, 6.5544],\n",
       "                        ...,\n",
       "                        [3.0348, 6.3622, 7.8398,  ..., 6.7617, 5.4710, 6.8917],\n",
       "                        [1.8291, 4.6612, 6.2682,  ..., 6.1743, 3.8168, 5.6124],\n",
       "                        [0.9591, 2.4425, 4.5888,  ..., 3.9529, 2.6183, 3.4394]],\n",
       "              \n",
       "                       [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        ...,\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]])),\n",
       "             ('15',\n",
       "              tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        ...,\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "              \n",
       "                       [[0.1346, 0.0000, 0.0000,  ..., 0.0000, 0.2442, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        ...,\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "              \n",
       "                       [[5.1621, 0.5190, 0.6024,  ..., 0.0000, 1.2120, 1.0189],\n",
       "                        [1.7505, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [1.7012, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        ...,\n",
       "                        [1.5335, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [2.1115, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.9748, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0.0000, 0.1943, 0.3878,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.5493, 0.0000,  ..., 0.0000, 0.0000, 0.2802],\n",
       "                        ...,\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1507, 1.4911],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "              \n",
       "                       [[3.5221, 4.7173, 3.9577,  ..., 3.5233, 4.2502, 4.3516],\n",
       "                        [7.1953, 8.2679, 6.5165,  ..., 5.5348, 8.4397, 6.5544],\n",
       "                        [7.0663, 7.2163, 6.3946,  ..., 5.4174, 7.7560, 6.1906],\n",
       "                        ...,\n",
       "                        [5.8753, 7.3897, 6.7276,  ..., 7.6118, 6.7231, 6.8866],\n",
       "                        [6.3622, 7.8398, 7.0615,  ..., 7.1938, 6.7617, 6.9746],\n",
       "                        [4.6612, 6.2682, 6.2948,  ..., 4.4189, 6.1743, 5.6124]],\n",
       "              \n",
       "                       [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        ...,\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]])),\n",
       "             ('19',\n",
       "              tensor([[[[0.2265, 0.0000, 0.0000,  ..., 0.0000, 0.4559, 0.0831],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0837,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        ...,\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "              \n",
       "                       [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        ...,\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "              \n",
       "                       [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        ...,\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        ...,\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "              \n",
       "                       [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0992],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        ...,\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3477],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "              \n",
       "                       [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        ...,\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]]))])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7102e531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "edf38811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (7): ReLU(inplace=True)\n",
      "  (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (9): ReLU(inplace=True)\n",
      "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (12): ReLU(inplace=True)\n",
      "  (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (14): ReLU(inplace=True)\n",
      "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (17): ReLU(inplace=True)\n",
      "  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (19): ReLU(inplace=True)\n",
      "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "image_model = models.vgg11(pretrained=False)\n",
    "checkpoint = torch.load('/models/cache/hub/checkpoints/vgg11-8a719046.pth')\n",
    "image_model.load_state_dict(checkpoint)\n",
    "\n",
    "newmodel = list(model.children())[0]\n",
    "print(newmodel)\n",
    "\n",
    "for parameter in newmodel.parameters():\n",
    "    parameter.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "794a8474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(newmodel._modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8d5cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in newmodel.parameters():\n",
    "    parameter.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc1263ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (7): ReLU(inplace=True)\n",
       "  (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (9): ReLU(inplace=True)\n",
       "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (12): ReLU(inplace=True)\n",
       "  (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (14): ReLU(inplace=True)\n",
       "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (17): ReLU(inplace=True)\n",
       "  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (19): ReLU(inplace=True)\n",
       "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.children())[0]\n",
    "\n",
    "[19,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e5c89a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_gate = torch.jit.script(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8ac3e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_gate.save('/models/vgg/wrapped_rnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3445c5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "197a8076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
      "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
      "              ReLU-7        [-1, 128, 112, 112]               0\n",
      "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
      "              ReLU-9        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
      "             ReLU-12          [-1, 256, 56, 56]               0\n",
      "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-14          [-1, 256, 56, 56]               0\n",
      "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-16          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
      "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
      "             ReLU-19          [-1, 512, 28, 28]               0\n",
      "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-21          [-1, 512, 28, 28]               0\n",
      "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-23          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
      "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-26          [-1, 512, 14, 14]               0\n",
      "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-28          [-1, 512, 14, 14]               0\n",
      "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-30          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
      "           Linear-33                 [-1, 4096]     102,764,544\n",
      "             ReLU-34                 [-1, 4096]               0\n",
      "          Dropout-35                 [-1, 4096]               0\n",
      "           Linear-36                 [-1, 4096]      16,781,312\n",
      "             ReLU-37                 [-1, 4096]               0\n",
      "          Dropout-38                 [-1, 4096]               0\n",
      "           Linear-39                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 218.78\n",
      "Params size (MB): 527.79\n",
      "Estimated Total Size (MB): 747.15\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchsummary import summary\n",
    "image_model = models.vgg16(pretrained=False)\n",
    "checkpoint = torch.load('/models/cache/hub/checkpoints/vgg16-397923af.pth')\n",
    "image_model.load_state_dict(checkpoint)\n",
    "image_model.cuda()\n",
    "summary(image_model, (3, 224, 224))\n",
    "\n",
    "# [19,18,15,13,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dfbdc190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU(inplace=True)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_model.features._modules['22']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7267934",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultimodalAttentionOld(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.L = 4\n",
    "        self.M = 18\n",
    "        self.gamma_1 = 5\n",
    "        self.gamma_2 = 10\n",
    " \n",
    "       \n",
    "        \n",
    "    def forward(self,word_feature, sentence_feature, image_feature,seq_lens):\n",
    "        \n",
    "        '''\n",
    "        word_feature dims (B,T,D)\n",
    "        image_feature dims (B,M,M,L,D)\n",
    "        '''\n",
    "        #reshape to (B,M,M,T,L,D)\n",
    "        batch_size = word_feature.shape[0]\n",
    "        word_image_max_score = self.get_pertinence_scores(word_feature,image_feature)\n",
    "        sentence_image_score = self.get_pertinence_scores(sentence_feature.unsqueeze(1),image_feature).squeeze(1)\n",
    "        \n",
    "        \n",
    "        aggregated_sentence_image_score = torch.exp(word_image_max_score * self.gamma_1) *  self.get_len_mask(batch_size , max_word_len,seq_lens)\n",
    "        aggregated_sentence_image_score = torch.log(torch.sum(aggregated_sentence_image_score,1) ** (1/self.gamma_1))\n",
    "        \n",
    "        return aggregated_sentence_image_score, sentence_image_score \n",
    "\n",
    "    def get_pertinence_scores(self,word_feature,image_feature):\n",
    "        reshaped_word_feature = word_feature.unsqueeze(1).unsqueeze(1).unsqueeze(4).expand(-1,self.M,self.M,-1,self.L,-1)\n",
    "        max_word_len = reshaped_word_feature.shape[3]\n",
    "        #reshape to (B,M,M,T,L,D)\n",
    "        reshaped_image_feature = image_feature.unsqueeze(3).expand(-1,-1,-1,max_word_len,-1,-1)\n",
    "        \n",
    "        #heatmap dims (B,M,M,T,L)\n",
    "        similarity_heatmap = F.relu(F.cosine_similarity(reshaped_word_feature,reshaped_image_feature,dim=5))\n",
    "        \n",
    "        # collapse image width and heigh dimensions into single dim for weighted summing via matrix mult\n",
    "        # reshape so that dimension to sum across is at the end  \n",
    "        # (B, T, L, 1, MXM)\n",
    "        similarity_heatmap_flat = torch.flatten(similarity_heatmap, start_dim=1, end_dim=2).permute(0,2,3,1).unsqueeze(3)\n",
    "        \n",
    "        # (B,T,L,MXM,D)\n",
    "        # collapse width and height dims for image_feature for weighted summing via matrix mult\n",
    "        image_feature_flat = torch.flatten(image_feature, start_dim=1, end_dim=2).permute(0,2,1,3).unsqueeze(1).expand(-1,max_word_len,-1,-1,-1)\n",
    "\n",
    "        visual_word_attention = torch.matmul(similarity_heatmap_flat,image_feature_flat).squeeze(3)\n",
    "        \n",
    "        #(B,T,L,D)\n",
    "        visual_word_attention = torch.nn.functional.normalize(visual_word_attention ,p=2,dim=3)\n",
    "        \n",
    "        #(B,T,L)\n",
    "        word_image_pertinence_score = F.cosine_similarity(word_feature.unsqueeze(2).expand(-1,-1,self.L,-1),visual_word_attention,dim=3)\n",
    "        \n",
    "        word_image_max_pertinence_score,_ = torch.max(word_image_pertinence_score,dim=2)\n",
    "        return word_image_max_pertinence_score\n",
    "    \n",
    "    def get_len_mask(self, batch_size, max_len, seq_lens):\n",
    "        \"\"\"Generates an 'upper-triangular matrix' with 1 in places without mask\"\"\"\n",
    "        block = torch.zeros(batch_size, max_len)\n",
    "        for i,l in enumerate(seq_lens):\n",
    "            block[i, :l] = torch.ones(1, l)\n",
    "        \n",
    "        return block.cuda()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
