{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58b4ef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Pytorch pre-release version 1.10.0a0+3fd9dcf - assuming intent to test it\n"
     ]
    }
   ],
   "source": [
    "from data.dataset import VisualGroundingDataset\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a719e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.token_indexers import ELMoTokenCharactersIndexer\n",
    "from allennlp.data.tokenizers import WhitespaceTokenizer\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.data.fields.text_field import TextField\n",
    "from allennlp.data.tokenizers.token_class import Token\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "indexer = ELMoTokenCharactersIndexer()\n",
    "vocab = Vocabulary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b84cbfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process(x):\n",
    "    x = tokenizer.tokenize(x)\n",
    "    text_field = TextField(x, {\"elmo_tokens\": indexer})\n",
    "    text_field.index(vocab)\n",
    "    token_tensor = text_field.as_tensor(\n",
    "                text_field.get_padding_lengths())\n",
    "    return token_tensor['elmo_tokens']['elmo_tokens']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8899b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.token_embedders import  ElmoTokenEmbedder\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.elmo import Elmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29cc2df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elmo embedder initialized on gpu?: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 26, 1024])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config.config import cfg\n",
    "dataset = VisualGroundingDataset('train', cfg)\n",
    "img, text,length = dataset[1]\n",
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a09b001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ff9c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'what the grade starter'\n",
    "x22 = 'what the grade graders s'\n",
    "x = process(x).unsqueeze(0)\n",
    "x2 = process(x22).unsqueeze(0)\n",
    "x3 = process(x22).unsqueeze(0)\n",
    "batch_x = [x,x2,x3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cb91172",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_878/3824863784.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m batch_pad_x = torch.nn.utils.rnn.pad_sequence(\n\u001b[0m\u001b[1;32m      2\u001b[0m             batch_x, batch_first=True,padding_value=261)\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpad_sequence\u001b[0;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;31m# assuming trailing dimensions and type of all the Tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;31m# in sequences are same and fetching those from sequences[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "batch_pad_x = torch.nn.utils.rnn.pad_sequence(\n",
    "            batch_x, batch_first=True,padding_value=261)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a93aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    print(batch_pad_x[1,:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "377e2d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 4, 50])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_pad_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c42a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexer = ELMoTokenCharactersIndexer()\n",
    "# vocab = lm_embedder._lm.vocab\n",
    "# character_indices = indexer.tokens_to_indices(tokens, vocab, \"elmo\")[\"elmo\"]\n",
    "\n",
    "# # Batch of size 1\n",
    "# indices_tensor = torch.LongTensor([character_indices])\n",
    "\n",
    "# # Embed and extract the single element from the batch.\n",
    "# embeddings = lm_embedder(indices_tensor)[0]\n",
    "\n",
    "# for word_embedding in embeddings:\n",
    "#   print(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e46225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_embedding._elmo._modules['_elmo_lstm']._elmo_lstm.stateful =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2116e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_options_file = (\n",
    "    \"/models/elmo/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\"\n",
    ")\n",
    "elmo_weight_file = (\n",
    "    \"/models/elmo/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\"\n",
    ")\n",
    "elmo_embedding = ElmoTokenEmbedder(\n",
    "    options_file=elmo_options_file, weight_file=elmo_weight_file, dropout=0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a76934",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_dict = {'elmo_tokens':{'elmo_tokens':batch_pad_x}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49949d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_tokens = elmo_embedding(x.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b82a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    embedded_tokens = embedder(tensor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87371376",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_pad_x[1,3] == batch_pad_x[2,3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893faf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedded_tokens[1].sum()) #first\n",
    "print(embedded_tokens[2].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac28d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaf522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "script =torch.jit.script(elmo_embedding)\n",
    "torch.jit.save(script, '/models/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da60c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedded_tokens[0].sum()) #second\n",
    "print(embedded_tokens[2].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5bbf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedded_tokens[0].sum()) #second\n",
    "print(embedded_tokens[2].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae40765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d47ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb54c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clearml import Dataset\n",
    "dataset_id = 'ab4ccbef42d646b28c4fe29b933a15ce'\n",
    "dataset = Dataset.get(dataset_id=dataset_id)\n",
    "local_root_path = dataset.get_mutable_local_copy(\n",
    "        os.path.join('/data/manifest', dataset_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec2053a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
